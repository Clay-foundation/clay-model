# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/01_embeddings.ipynb.

# %% auto 0
__all__ = ['EmbeddingsFactory', 'EmbeddingsHandler']

# %% ../nbs/01_embeddings.ipynb 2
from nbdev.showdoc import *
import geopandas as gpd
from datetime import datetime
import numpy as np
from tqdm import tqdm
import geopandas as gpd
import pandas as pd
from pathlib import Path
import contextily as ctx
import matplotlib.pyplot as plt
from concurrent.futures import ProcessPoolExecutor
from shapely.geometry import Point
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import os
from PIL import Image
import rasterio
import matplotlib.pyplot as plt


# %% ../nbs/01_embeddings.ipynb 6
class EmbeddingsFactory:
    def __init__(self, model, output_directory):
        """
        Initializes the Embeddings Factory with a model and an output directory.
        """
        self.model = model
        self.output_directory = output_directory

    def generate_embeddings(self, location_geojson, start_date, end_date, source):
        """
        Generates embeddings for a given location and time range.
        """

    def _save_embeddings(self, embeddings, feature, start_date, end_date):
        """
        Saves the embeddings to a file or S3.
        """


# %% ../nbs/01_embeddings.ipynb 9
class EmbeddingsHandler:
    def __init__(self, 
                path: Path, #Path to the file or folder with files
                max_files: [None,int] = None): #Max number of files to load, randomly chosen
        self.path = Path(path)
        self.gdf = None
        self.files = None
        
        #handle path
        if self.path.is_dir():
            assert self.path.exists(), 'Path does not exist'
            self.files=list(self.path.glob('*.gpq'))
            if max_files is not None:
                self.files = np.random.choice(self.files, max_files)

            assert len(self.files) > 0, 'No gpq files found in path'
        else:
            self.files=[self.path]
            assert self.path.suffix == '.gpq', 'File must be a gpq file'

    def load_data(self,):
        "Load data from file"
        with ProcessPoolExecutor() as executor:
            gdfs = list(tqdm(executor.map(self.read_embeddings_file, self.files), total=len(self.files)))
        print(f'Total rows: {sum([len(gdf) for gdf in gdfs])}\n Merging dataframes...')
        self.gdf = pd.concat(gdfs, ignore_index=True)
        print('Done!\n Total rows: ', len(self.gdf))
    
    def read_embeddings_file(self, file:Path ): 
        assert file.exists(), 'Path does not exist'
        #check pattern of file name like 33PWP_20181021_20200114_v001.gpq
        assert file.suffix == '.gpq', 'File must be a gpq file'
        parts=file.stem.split('_')
        assert len(parts) == 4, 'File name must have 4 parts'
        location, start_date, end_date, version = parts

        #read file
        gdf = gpd.read_parquet(file)
        gdf = gdf.to_crs('EPSG:3857')


        #add centroid x and y columns
        gdf['x'] = gdf.geometry.centroid.x
        gdf['y'] = gdf.geometry.centroid.y

        #set columns for the values of location, start_date, end_date, version
        gdf['location'] = location
        gdf['start_date'] = datetime.strptime(start_date, '%Y%m%d')
        gdf['end_date'] = datetime.strptime(end_date, '%Y%m%d')
        gdf['version'] = version
        return gdf
        

    def transform_crs(self, 
                    crs='epsg:3857'): #CRS to transform to
        self.gdf = self.gdf.to_crs(crs)

    def plot(self, 
            figsize:[int,int] =(10, 10), #Size of the plot
            alpha:float=0.2, #Transparency of the points
            edgecolor:str='k', #Color of the edges of the points
            max_rows: [int,None]=10000, #Max number of rows to plot
            bounds=None): #Bounds of the plot
       
        # If more points than max_rows, sample points for plotting
        if max_rows is not None and len(self.gdf) > max_rows:
            self.gdf = self.gdf.drop_duplicates(subset=['geometry'])
            self.gdf['geometry'] = [Point(xy) for xy in zip(self.gdf['x'], self.gdf['y'])]
            self.gdf = self.gdf.drop_duplicates(subset=['geometry'])
            print(f'Warning: {len(self.gdf)} is more than {max_rows} rows, sampling {max_rows} ({100 * max_rows / len(self.gdf):.3f}%) and converting to points for plotting')
            
            ax = self.gdf.sample(max_rows).reset_index(drop=True).plot(figsize=figsize, alpha=alpha, edgecolor=edgecolor, markersize=1)
        else:
            ax = self.gdf.plot(figsize=figsize, alpha=alpha, edgecolor=edgecolor, markersize=1)

        # If bounds are provided, set the bounds of the plot
        if bounds is not None:
            ax.set_xlim(bounds[0], bounds[1])
            ax.set_ylim(bounds[2], bounds[3])

        ctx.add_basemap(ax, source=ctx.providers.OpenStreetMap.Mapnik)
        ax.set_axis_off()
        plt.show()

    def local_imgs(self,
                   local_folder:Path): #replace s3 url with local folder
        
        #check if local_folder exists
        assert local_folder.exists(), f"{local_folder} does not exist"
        #check if local_folder has images
        assert len(list(local_folder.rglob('*.tif'))) > 0, f"{local_folder} does not have any images"
        
        # Replace the URL with a local folder
        self.gdf['tif_local_path'] = self.gdf['source_url'].str.replace('s3://', str(local_folder)+"/").apply(Path)

        # check if the image file exists, and replace with None if it doesn't
        # self.gdf['tif_local_path'] = self.gdf['tif_local_path']\
        #                             .apply(lambda x: x if os.path.isfile(x) else None)
        
        # check if any images were found
        assert self.gdf['tif_local_path'].notnull().any(), f"No local image paths found on {local_folder}"


    def image_sample(self, 
                     n:int, #number of random images to show
                     local_folder:Path=None):
        
        #check if local path exists, call local_imgs() if not
        if 'tif_local_path' not in self.gdf.columns:
            self.local_imgs(local_folder)

        # Of those, get a random sample of n rows
        if len(self.gdf['tif_local_path'].notnull())<=n:
            print(f'Warning: {len(self.gdf["tif_local_path"].notnull())} is less than {n} rows, returning all available rows')
            sample = self.gdf[self.gdf['tif_local_path'].notnull()]
        else:
            sample = self.gdf[self.gdf['tif_local_path'].notnull()].sample(n)

        
        nrows = int(np.ceil(n/3))
        ncols = 3 if n > 3 else n  # adjust number of columns based on n
        fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(20, 20))
        if nrows == 1:
            axes = axes[np.newaxis, :]
        for i, ax in enumerate(axes.flatten()):
            if i < n:  # check if we have an image for this subplot
                with rasterio.open(str(sample['tif_local_path'].iloc[i])) as src:
                    img = src.read([3, 4, 2])  # read the first three bands
                img = (img - img.min()) / (img.max() - img.min())
                img = np.transpose(img, [1, 2, 0])
                ax.imshow(img)  # use ax to call imshow
            else:
                ax.axis('off')  # hide extra subplots

        plt.show()

