{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "287c93e9",
   "metadata": {},
   "source": [
    "# Digital Earth Pacific mineral resource detection using Clay\n",
    "\n",
    "This notebook applies the Clay model on imagery composites, specifically a Sentinel-2\n",
    "Geometric Median [(GeoMAD)](https://docs.digitalearthafrica.org/en/latest/data_specs/GeoMAD_specs.html) composite. We will use\n",
    "[Digital Earth Pacific's STAC API](https://stac-browser.staging.digitalearthpacific.org)\n",
    "to obtain these datasets, and apply it on a mineral resource detection downstream task to do the following:\n",
    "\n",
    "1. Generate fine level (pixel of size 10m x 10m) embeddings for an area (5.12km x 5.12km) where known mining extraction is occurring\n",
    "2. Save the fine level (patch) embeddings and execute a similarity search that leverages the ground truth points as reference\n",
    "\n",
    "This is a demonstration of how one can use Clay to identify possible new events provided a reference dataset for where known events occur.\n",
    "\n",
    "References:\n",
    "- https://github.com/digitalearthpacific/mineral-resource-detection\n",
    "- https://github.com/Clay-foundation/model/discussions/140"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9b0dbed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pystac_client\n",
    "import shapely\n",
    "import stackstac\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import random\n",
    "import rasterio\n",
    "import rioxarray  # noqa: F401\n",
    "import pyarrow as pa\n",
    "import pickle\n",
    "import lancedb\n",
    "import glob\n",
    "from pathlib import Path\n",
    "from shapely.geometry import Point, Polygon, box\n",
    "from rasterio.enums import Resampling\n",
    "from src.datamodule import ClayDataModule\n",
    "from src.model_clay import CLAYModule\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "BAND_GROUPS = {\n",
    "    \"rgb\": [\"B04\", \"B03\", \"B02\"],\n",
    "    \"rededge\": [\"B05\", \"B06\", \"B07\", \"B8A\"],\n",
    "    \"nir\": [\"B08\"],\n",
    "    \"swir\": [\"B11\", \"B12\"],\n",
    "    \"sar\": [\"mean_vv\", \"mean_vh\"],\n",
    "}\n",
    "\n",
    "STAC_API = \"https://stac.staging.digitalearthpacific.org\"\n",
    "COLLECTION = \"dep_s2_geomad\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03fa77d3",
   "metadata": {},
   "source": [
    "## Find the Sentinel-2 composite stored as a Cloud-Optimized GeoTIFF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d63dc31-aea8-4e9a-97cc-55f30ffd0893",
   "metadata": {},
   "source": [
    "#### Read the mining extraction ground truth points\n",
    "We will use these for reference in a similarity search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26f3f22b-599d-46ea-8a23-df10ab5826e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mrd = gpd.read_file(\n",
    "    \"https://raw.githubusercontent.com/digitalearthpacific/mineral-resource-detection/d117d04703f77ff21c15c7ffc424c3c55b51c492/training_data/draft_inputs/MRD_dissagregated_25.geojson\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "070192b4-c5fd-4632-bcce-bd476eab8f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming mining extraction relates to the quarry lulc class\n",
    "mrd_mining = mrd[mrd[\"lulc_class\"] == 'quarry']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5dbed204-71f9-4ac0-8bb5-b3496024635f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extent of the mining extraction activity per the ground truth reference points\n",
    "mrd_mining_bounds = mrd_mining.total_bounds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda4d759-2c2b-430a-b4b8-21ebd0c4ccbb",
   "metadata": {},
   "source": [
    "#### Find a \"hotspot\" area\n",
    "Since we are demoing a single 512x512 tile in this tutorial, let's identify a cluster where several ground truth points exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "adb0b69a-faa2-4bfc-9cdd-d2294de9bec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample cluster\n",
    "bbox_bl = (177.4199,-17.8579)\n",
    "bbox_tl = (177.4156,-17.6812)\n",
    "bbox_br = (177.5657,-17.8572)\n",
    "bbox_tr = (177.5657,-17.6812)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e30686-7555-4866-8157-752418174140",
   "metadata": {},
   "source": [
    "Define spatiotemporal query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a1ac2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define area of interest\n",
    "area_of_interest = shapely.box(xmin=bbox_bl[0], ymin=bbox_bl[1], xmax=bbox_tr[0], ymax=bbox_tr[1])\n",
    "\n",
    "# Define temporal range\n",
    "daterange: dict = [\"2021-01-01T00:00:00Z\", \"2021-12-31T23:59:59Z\"] # one annual composite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4e6aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog = pystac_client.Client.open(url=STAC_API)\n",
    "\n",
    "sen2_search = catalog.search(\n",
    "    collections=[COLLECTION],\n",
    "    datetime=daterange,\n",
    "    intersects=area_of_interest,\n",
    "    max_items=100,\n",
    ")\n",
    "\n",
    "items = sen2_search.get_all_items()\n",
    "\n",
    "print(f\"Found {len(items)} items\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d5183d",
   "metadata": {},
   "source": [
    "## Download the data\n",
    "Get the composite data into a numpy array and visualize the imagery. STAC browser URL is at\n",
    "https://stac-browser.staging.digitalearthpacific.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cccf2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract coordinate system from first item\n",
    "epsg = items[0].properties[\"proj:epsg\"]\n",
    "\n",
    "# Convert point from lon/lat to UTM projection\n",
    "poidf = gpd.GeoDataFrame(crs=\"OGC:CRS84\", geometry=[area_of_interest.centroid]).to_crs(\n",
    "    epsg\n",
    ")\n",
    "geom = poidf.iloc[0].geometry\n",
    "\n",
    "# Create bounds of the correct size, the model\n",
    "# requires 512x512 pixels at 10m resolution.\n",
    "bounds = (geom.x - 2560, geom.y - 2560, geom.x + 2560, geom.y + 2560)\n",
    "\n",
    "# Retrieve the pixel values, for the bounding box in\n",
    "# the target projection. In this example we use only\n",
    "# the RGB and NIR band groups.\n",
    "stack = stackstac.stack(\n",
    "    items,\n",
    "    bounds=bounds,\n",
    "    snap_bounds=False,\n",
    "    epsg=epsg,\n",
    "    resolution=10,\n",
    "    dtype=\"float32\",\n",
    "    rescale=False,\n",
    "    fill_value=0,\n",
    "    assets=BAND_GROUPS[\"rgb\"] + BAND_GROUPS[\"nir\"],\n",
    "    resampling=Resampling.nearest,\n",
    ")\n",
    "\n",
    "stack = stack.compute()\n",
    "assert stack.shape == (1, 4, 512, 512)\n",
    "\n",
    "stack.sel(band=[\"B04\", \"B03\", \"B02\"]).plot.imshow(\n",
    "    row=\"time\", rgb=\"band\", vmin=0, vmax=2000\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33de5456-3590-4e31-867e-4fed1a88d08b",
   "metadata": {},
   "source": [
    "#### Write the stack to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e4afb6d-cfed-48ec-a960-046063190cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "outdir = Path(\"data/minicubes\")\n",
    "outdir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "write = True\n",
    "if write:\n",
    "    # Write tile to output dir\n",
    "    for tile in stack:\n",
    "        date = str(tile.time.values)[:10]\n",
    "    \n",
    "        name = \"{dir}/claytile_{date}.tif\".format(\n",
    "            dir=outdir,\n",
    "            date=date.replace(\"-\", \"\"),\n",
    "        )\n",
    "        tile.rio.to_raster(name, compress=\"deflate\")\n",
    "    \n",
    "        with rasterio.open(name, \"r+\") as rst:\n",
    "            rst.update_tags(date=date)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0f37d4-35bf-4aa8-afb6-20f37d5739c2",
   "metadata": {},
   "source": [
    "### Get the geospatial bounds for the 32x32 windows \n",
    "We will use the geospatial bounds of the 32x32 windowed subsets (\"chunks\") to store the patch level embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "22aa5c54-5336-4b52-a927-6748448a146d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the chunk size for tiling\n",
    "chunk_size = {'x': 32, 'y': 32}  # Adjust the chunk size as needed\n",
    "\n",
    "# Tile the data\n",
    "ds_chunked = stack.chunk(chunk_size)\n",
    "\n",
    "# Get the dimensions of the data array\n",
    "dims = ds_chunked.dims\n",
    "\n",
    "# Get the geospatial information from the original dataset\n",
    "geo_info = ds_chunked.attrs\n",
    "\n",
    "# Iterate over the chunks and compute the geospatial bounds for each chunk\n",
    "chunk_bounds = {}\n",
    "\n",
    "# Get the geospatial transform and CRS\n",
    "transform = ds_chunked.attrs['transform']\n",
    "crs = ds_chunked.attrs['crs']\n",
    "\n",
    "for x in range((ds_chunked.sizes['x'] // chunk_size['x']) + 1):\n",
    "    for y in range((ds_chunked.sizes['y'] // chunk_size['y']) + 1):\n",
    "        # Compute chunk coordinates\n",
    "        x_start = x * chunk_size['x']\n",
    "        y_start = y * chunk_size['y']\n",
    "        x_end = min(x_start + chunk_size['x'], ds_chunked.sizes['x'])\n",
    "        y_end = min(y_start + chunk_size['y'], ds_chunked.sizes['y'])\n",
    "        \n",
    "        # Compute chunk geospatial bounds\n",
    "        lon_start, lat_start = transform * (x_start, y_start)\n",
    "        lon_end, lat_end = transform * (x_end, y_end)\n",
    "        #print(lon_start, lat_start, lon_end, lat_end, x, y)\n",
    "\n",
    "        # Store chunk bounds\n",
    "        chunk_bounds[(x, y)] = {\n",
    "            'lon_start': lon_start, 'lat_start': lat_start,\n",
    "            'lon_end': lon_end, 'lat_end': lat_end\n",
    "        }\n",
    "\n",
    "# Print chunk bounds\n",
    "#for key, value in chunk_bounds.items():\n",
    "    #print(f\"Chunk {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b343a9b5-e1e2-4aad-aaa3-b159302b5766",
   "metadata": {},
   "source": [
    "### Generate embeddings for the full or partial inputs\n",
    "We will generate patch level embeddings averaged over the band groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0128e13d-3171-4412-8a73-b510120d5741",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"data/minicubes\"\n",
    "CKPT_PATH = \"https://huggingface.co/made-with-clay/Clay/resolve/main/Clay_v0.1_epoch-24_val-loss-0.46.ckpt\"\n",
    "\n",
    "# Load model\n",
    "multi_model = CLAYModule.load_from_checkpoint(\n",
    "    CKPT_PATH,\n",
    "    mask_ratio=0.0,\n",
    "    band_groups={\"rgb\": (2, 1, 0), \"nir\": (3,)},\n",
    "    bands=4,\n",
    "    strict=False,  # ignore the extra parameters in the checkpoint\n",
    "    embeddings_level=\"group\",\n",
    ")\n",
    "# Set the model to evaluation mode\n",
    "multi_model.eval()\n",
    "\n",
    "\n",
    "# Load the datamodule, with the reduced set of\n",
    "class ClayDataModuleMulti(ClayDataModule):\n",
    "    MEAN = [\n",
    "        1369.03,  # red\n",
    "        1597.68,  # green\n",
    "        1741.10,  # blue\n",
    "        2893.86,  # nir\n",
    "    ]\n",
    "    STD = [\n",
    "        2026.96,  # red\n",
    "        2011.88,  # green\n",
    "        2146.35,  # blue\n",
    "        1917.12,  # nir\n",
    "    ]\n",
    "\n",
    "\n",
    "data_dir = Path(DATA_DIR)\n",
    "\n",
    "dm = ClayDataModuleMulti(data_dir=str(data_dir.absolute()), batch_size=1)\n",
    "dm.setup(stage=\"predict\")\n",
    "trn_dl = iter(dm.predict_dataloader())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348da3fb-adfb-4271-a5ab-72dd13854a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = []\n",
    "for batch in trn_dl:\n",
    "    with torch.no_grad():\n",
    "        # Move data from to the device of model\n",
    "        batch[\"pixels\"] = batch[\"pixels\"].to(multi_model.device)\n",
    "        # Pass just the specific band through the model\n",
    "        batch[\"timestep\"] = batch[\"timestep\"].to(multi_model.device)\n",
    "        batch[\"latlon\"] = batch[\"latlon\"].to(multi_model.device)\n",
    "\n",
    "        # Pass pixels, latlon, timestep through the encoder to create encoded patches\n",
    "        (\n",
    "            unmasked_patches,\n",
    "            unmasked_indices,\n",
    "            masked_indices,\n",
    "            masked_matrix,\n",
    "        ) = multi_model.model.encoder(batch)\n",
    "        print(unmasked_patches.detach().cpu().numpy())\n",
    "\n",
    "        embeddings.append(unmasked_patches.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174e0c28-5a6b-4bcc-8749-d2db0d05e465",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(embeddings[0])) # embeddings is a list\n",
    "print(embeddings[0].shape) # with date and lat/lon\n",
    "print(embeddings[0][:, :-2, :].shape) # remove date and lat/lon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "248ffd8e-d22f-4924-b446-dc4e4433f1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove date and lat/lon and reshape to disaggregated patches\n",
    "embeddings_patch = embeddings[0][:, :-2, :].reshape([2,16,16,768]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f3f367-a7f9-440b-944c-42eaae77d7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_patch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "56475796-123c-40d1-884d-ab3860954738",
   "metadata": {},
   "outputs": [],
   "source": [
    "# average over the band groups\n",
    "embeddings_patch_avg_group = embeddings_patch.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762c91fa-78d6-42c8-9c98-7fbe3365567d",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_patch_avg_group.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0339a225-73b3-409d-a40e-e60266a2bcb8",
   "metadata": {},
   "source": [
    "### Save the patch level embeddings to independent GeoParquet files\n",
    "Save the patch level embeddings with the matching geospatial bounds from the chunks we computed earlier. We are correlating patch to chunk bounds based on matching index. This assumes the patches and chunks both define 32x32 subsets with zero overlap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b8cabf45-e1ab-417c-8db7-3f3c988c0285",
   "metadata": {},
   "outputs": [],
   "source": [
    "outdir_embeddings = Path(\"data/embeddings\")\n",
    "outdir_embeddings.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40113c9-feb9-4bde-911d-ba33f3d0ac25",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Iterate through each patch\n",
    "for i in range(embeddings_patch_avg_group.shape[0]):\n",
    "    for j in range(embeddings_patch_avg_group.shape[1]):\n",
    "        embeddings_output_patch = embeddings_patch_avg_group[i, j]\n",
    "\n",
    "        item_ = [element for element in list(chunk_bounds.items()) if element[0] == (i,j)]\n",
    "        box_ = [item_[0][1]['lon_start'], item_[0][1]['lat_start'],\n",
    "                item_[0][1]['lon_end'], item_[0][1]['lat_end']]\n",
    "        source_url = batch[\"source_url\"]\n",
    "        date = batch[\"date\"]\n",
    "        data = {\n",
    "            \"source_url\": batch[\"source_url\"][0],\n",
    "            \"date\": pd.to_datetime(arg=date, format=\"%Y-%m-%d\").astype(dtype=\"date32[day][pyarrow]\"),\n",
    "            \"embeddings\": [numpy.ascontiguousarray(embeddings_output_patch)]\n",
    "        }\n",
    "        \n",
    "        # Define the bounding box as a Polygon (xmin, ymin, xmax, ymax)\n",
    "        # The box_ list is encoded as [bottom left x, bottom left y, top right x, top right y]\n",
    "        box_emb = shapely.geometry.box(box_[0], box_[1], box_[2], box_[3])\n",
    "        \n",
    "        # Create the GeoDataFrame\n",
    "        gdf = gpd.GeoDataFrame(data, geometry=[box_emb], crs=f\"EPSG:{epsg}\")\n",
    "        \n",
    "        # Reproject to WGS84 (lon/lat coordinates)\n",
    "        gdf = gdf.to_crs(epsg=4326)\n",
    "\n",
    "        outpath = f\"{outdir_embeddings}/{batch['source_url'][0].split('/')[-1][:-4]}_{i}_{j}.gpq\"\n",
    "        gdf.to_parquet(path=outpath, compression=\"ZSTD\", schema_version=\"1.0.0\")\n",
    "        print(\n",
    "            f\"Saved {len(gdf)} rows of embeddings of \"\n",
    "            f\"shape {gdf.embeddings.iloc[0].shape} to {outpath}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e3765d-da9e-4cac-b766-e00c8d29816b",
   "metadata": {},
   "source": [
    "### Similarity search on the patch embedding level\n",
    "We will use reference lon,lat points from the ground truth mining extraction data to define a filtered search where a point maps to its overlapping patch, and that patch is used to find similar patches (aka potential new mining extraction sites)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1997f712-c45d-4d2e-81db-d3fa335a0f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = lancedb.connect(\"embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a013a684-a689-4f5b-8994-ba74dc76f6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data for DB table\n",
    "data = []\n",
    "# Dataframe to find overlaps within\n",
    "gdfs = []\n",
    "for emb in glob.glob(f\"{outdir_embeddings}/*.gpq\"):\n",
    "    gdf = gpd.read_parquet(emb)\n",
    "    gdf[\"year\"] = gdf.date.dt.year\n",
    "    gdf[\"tile\"] = gdf[\"source_url\"].apply(lambda x: Path(x).stem.rsplit(\"/\")[-1].rsplit(\"_\")[0])\n",
    "    gdf[\"idx\"] = '_'.join(emb.split(\"/\")[-1].split(\"_\")[2:]).replace('.gpq', '')\n",
    "    gdf[\"box\"] = [box(*geom.bounds) for geom in gdf.geometry]\n",
    "    gdfs.append(gdf)\n",
    "    \n",
    "    for _,row in gdf.iterrows():\n",
    "        data.append({\n",
    "            \"vector\": row[\"embeddings\"],\n",
    "            \"path\": row[\"source_url\"],\n",
    "            \"tile\": row[\"tile\"],\n",
    "            \"date\": row[\"date\"],\n",
    "            \"year\": int(row[\"year\"]),\n",
    "            \"idx\": row[\"idx\"],\n",
    "            \"box\": row[\"box\"].bounds,\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "522fdf1e-dbc0-4416-8235-49f653405e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine patch level geodataframes into one\n",
    "embeddings_gdf = pd.concat(gdfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e461223-b432-44c1-8233-c3258b5b72af",
   "metadata": {},
   "source": [
    "##### (Optional) check on what an embedding's RGB subset looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6f4cfb-554b-4c2d-be5d-bc582f1638b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_gdf_shuffled = embeddings_gdf.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "area_of_interest_embedding = embeddings_gdf_shuffled.box.iloc[0]\n",
    "\n",
    "# Extract coordinate system from first item\n",
    "epsg = items[0].properties[\"proj:epsg\"]\n",
    "\n",
    "# Convert point from lon/lat to UTM projection\n",
    "box_embedding = gpd.GeoDataFrame(crs=\"OGC:CRS84\", \n",
    "                                 geometry=[area_of_interest_embedding]).to_crs(epsg)\n",
    "geom_embedding = box_embedding.iloc[0].geometry\n",
    "\n",
    "# Create bounds of the correct size, the model\n",
    "# requires 32x32 pixels at 10m resolution.\n",
    "\n",
    "# Retrieve the pixel values, for the bounding box in\n",
    "# the target projection. In this example we use only\n",
    "# the RGB and NIR band groups.\n",
    "stack_embedding = stackstac.stack(\n",
    "    items,\n",
    "    bounds=geom_embedding.bounds,\n",
    "    snap_bounds=False,\n",
    "    epsg=epsg,\n",
    "    resolution=10,\n",
    "    dtype=\"float32\",\n",
    "    rescale=False,\n",
    "    fill_value=0,\n",
    "    assets=BAND_GROUPS[\"rgb\"] + BAND_GROUPS[\"nir\"],\n",
    "    resampling=Resampling.nearest,\n",
    ")\n",
    "\n",
    "stack_embedding = stack_embedding.compute()\n",
    "assert stack_embedding.shape == (1, 4, 32, 32)\n",
    "\n",
    "stack_embedding.sel(band=[\"B04\", \"B03\", \"B02\"]).plot.imshow(\n",
    "    row=\"time\", rgb=\"band\", vmin=0, vmax=2000\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e1b2be-1cf4-4ff9-80ca-bb49ec4c75f9",
   "metadata": {},
   "source": [
    "#### Instantiate a dedicated DB table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e352b670-98fb-4a88-9965-08102278113c",
   "metadata": {},
   "outputs": [],
   "source": [
    "db.drop_table(\"clay-v001\")\n",
    "db.table_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48809b81-5f95-4841-97a2-f65bb318b4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl = db.create_table(\"clay-v001\", data=data, mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5a3352b0-b4eb-48fd-8ac6-335214ca6778",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = tbl.head(1).to_pandas()[\"vector\"].values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b9e76a-6489-4c9f-9947-7ee7abceba3d",
   "metadata": {},
   "source": [
    "#### Find the intersections of ground truth mining extraction points with patch embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1004c5fe-9a7a-4824-a486-1959c2b1302b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Function to check if a point intersects with a bounding box\n",
    "def check_intersection(row):\n",
    "    return point.intersects(row['box'])\n",
    "\n",
    "intersecting_rows_ = []\n",
    "for i, row in mrd_mining.iterrows():\n",
    "    # Create a Point geometry from the latitude and longitude\n",
    "    point = Point(row.x, row.y)\n",
    "    #print(point)\n",
    "\n",
    "    # Apply the function to each row of the DataFrame\n",
    "    intersects = embeddings_gdf.apply(check_intersection, axis=1)\n",
    "\n",
    "    # Get the rows where the point intersects with the bounding box\n",
    "    intersecting_rows = embeddings_gdf[intersects]\n",
    "    if not intersecting_rows.empty:\n",
    "        #print(intersecting_rows)\n",
    "        intersecting_rows_.append(intersecting_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ba45fe-49ce-42b9-8d1a-4224fbe2d061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of intersections in our AOI (which depicts a cluster)\n",
    "len(intersecting_rows_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51d956e-ac95-4774-9575-0d9199653454",
   "metadata": {},
   "source": [
    "#### Set up a filtered search to find 10 patches similar to the first intersecting patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "96bfbb07-82c8-4c74-8fdf-a9994e445a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_number = random.randint(0, len(intersecting_rows_)-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9cfd6379-4d61-4acf-aa2e-cc4e6d72e415",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference = tbl.to_pandas().query(\n",
    "    f\"idx == '{intersecting_rows_[reference_number].idx.values[0]}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "50c71702-1e70-443c-abc6-e22a5985de14",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = tbl.search(query=reference.iloc[0][\"vector\"]).limit(10).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4540ca81-f081-4765-b283-16c0b7782960",
   "metadata": {},
   "outputs": [],
   "source": [
    "#result.head(10)\n",
    "result.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae78d629-bf8f-4be4-95e7-c1b348fe22a8",
   "metadata": {},
   "source": [
    "### Plot similar patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dcc21df7-de1f-43bf-b593-f1f435627677",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(df, cols=10):\n",
    "    fig, axs = plt.subplots(1, cols, figsize=(20, 10))\n",
    "\n",
    "    row_0 = df.iloc[0]\n",
    "    path = row_0[\"path\"]\n",
    "    chip = rasterio.open(path)\n",
    "    tile = row_0[\"tile\"]\n",
    "    width = chip.width\n",
    "    height = chip.height\n",
    "    # Define the window size\n",
    "    window_size = (32, 32)\n",
    "\n",
    "    idxs_windows = {'idx': [], 'window': []}\n",
    "\n",
    "    # Iterate over the image in 32x32 windows\n",
    "    for col in range(0, width, window_size[0]):\n",
    "        for row in range(0, height, window_size[1]):\n",
    "            # Define the window\n",
    "            window = ((row, row + window_size[1]), (col, col + window_size[0]))\n",
    "            \n",
    "            # Read the data within the window\n",
    "            data = chip.read(window=window)\n",
    "            \n",
    "            # Get the index of the window\n",
    "            index = (col // window_size[0], row // window_size[1])\n",
    "            \n",
    "            # Process the window data here\n",
    "            # For example, print the index and the shape of the window data\n",
    "            #print(\"Index:\", index)\n",
    "            #print(\"Window Shape:\", data.shape)\n",
    "\n",
    "            idxs_windows['idx'].append('_'.join(map(str, index)))\n",
    "            idxs_windows['window'].append(data)\n",
    "            \n",
    "    #print(idxs_windows)\n",
    "    \n",
    "    for ax, (_, row) in zip(axs.flatten(), df.iterrows()):\n",
    "        idx = row[\"idx\"]\n",
    "        # Find the corresponding window based on the idx\n",
    "        window_index = idxs_windows['idx'].index(idx)\n",
    "        window_data = idxs_windows['window'][window_index]\n",
    "        #print(window_data.shape)\n",
    "        subset_img = numpy.clip((window_data.transpose(1,2,0)[:, :, :3]/10_000) * 3, 0,1)\n",
    "        ax.imshow(subset_img)\n",
    "        ax.set_title(f\"{tile}/{idx}\")\n",
    "        ax.set_axis_off()\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(\"similar.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3185baae-393c-4db4-95e7-bf5c6ab04842",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0819338-594b-401f-98b0-b6e5365ef73a",
   "metadata": {},
   "source": [
    "#### Visualize the area of interest with the ground truth mining points and similar patches\n",
    "\n",
    "The reference patch will be plotted in yellow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fc29a3-da6c-4928-b16a-c9863e21d828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a geodataframe of the search results\n",
    "result_boxes = [Polygon([(bbox[0], bbox[1]), (bbox[2], bbox[1]),\n",
    "                         (bbox[2], bbox[3]), (bbox[0], bbox[3])])\n",
    "                            for bbox in result['box']]\n",
    "result_gdf = gpd.GeoDataFrame(result, geometry=result_boxes)\n",
    "result_gdf.crs = \"EPSG:4326\"\n",
    "\n",
    "# Plot the AOI in RGB\n",
    "stack.sel(band=[\"B04\", \"B03\", \"B02\"]).plot.imshow(row=\"time\", rgb=\"band\", vmin=0, vmax=2000)\n",
    "\n",
    "# Overlay the bounding boxes of the patches identified from the similarity search\n",
    "result_gdf.to_crs(epsg).plot(ax=plt.gca(), color='red', alpha=0.5)\n",
    "\n",
    "# Reference embedding\n",
    "reference_gdf = gpd.GeoDataFrame(intersecting_rows_[reference_number],\n",
    "                                 geometry=intersecting_rows_[reference_number]['box'])\n",
    "reference_gdf.to_crs(epsg).plot(ax=plt.gca(), color='yellow', alpha=0.5)\n",
    "\n",
    "# Overlay the ground truth quarry points\n",
    "mrd_mining.to_crs(epsg).cx[\n",
    "    bounds[0]:bounds[2], bounds[1]:bounds[3]\n",
    "    ].plot(ax=plt.gca(), color='blue', markersize=5)\n",
    "\n",
    "\n",
    "# Set plot title and labels\n",
    "plt.title('Sentinel-2 with ground truth and similar embeddings')\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06d6090-8c87-43e4-997b-6ea464b20a40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
