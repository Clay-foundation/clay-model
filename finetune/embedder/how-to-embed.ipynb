{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9960547-640d-425c-8180-fc5523a80e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import requests\n",
    "import warnings\n",
    "\n",
    "import geoarrow.pyarrow as ga\n",
    "import numpy as np\n",
    "import pystac_client\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import torch\n",
    "import yaml\n",
    "from box import Box\n",
    "from torchvision.transforms import v2\n",
    "\n",
    "from stacchip.indexer import Sentinel2Indexer\n",
    "from stacchip.chipper import Chipper\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598fec81-2cc1-4c5a-9e46-7c46a5591484",
   "metadata": {},
   "source": [
    "### Find data for AOI\n",
    "The first step is to find STAC items of imagery that we want to use to create embeddings. In this example we are going to use Earth Genome's composite dataset which comes with a great STAC catalog.\n",
    "\n",
    "We are also going to create embeddings along time so that we have multiple embeddings for the same location at different moments in time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e1d46ee-40f6-49f5-99ad-83819339561e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Point over Monchique Portugal\n",
    "lat, lon = 37.30939, -8.57207\n",
    "\n",
    "# Dates of a large forest fire\n",
    "start = \"2018-07-01\"\n",
    "end = \"2018-09-01\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7825318-23f3-449f-9104-eae6562a55ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12 items\n"
     ]
    }
   ],
   "source": [
    "# Optimize GDAL settings for cloud optimized reading\n",
    "os.environ[\"GDAL_DISABLE_READDIR_ON_OPEN\"] = \"EMPTY_DIR\"\n",
    "os.environ[\"AWS_REQUEST_PAYER\"] = \"requester\"\n",
    "\n",
    "STAC_API = \"https://earth-search.aws.element84.com/v1\"\n",
    "COLLECTION = \"sentinel-2-l2a\"\n",
    "\n",
    "# Search the catalogue\n",
    "catalog = pystac_client.Client.open(STAC_API)\n",
    "search = catalog.search(\n",
    "    collections=[COLLECTION],\n",
    "    datetime=f\"{start}/{end}\",\n",
    "    bbox=(lon - 1e-5, lat - 1e-5, lon + 1e-5, lat + 1e-5),\n",
    "    max_items=100,\n",
    "    query={\"eo:cloud_cover\": {\"lt\": 80}},\n",
    ")\n",
    "\n",
    "all_items = search.get_all_items()\n",
    "\n",
    "# Reduce to one per date (there might be some duplicates\n",
    "# based on the location)\n",
    "items = []\n",
    "dates = []\n",
    "for item in all_items:\n",
    "    if item.datetime.date() not in dates:\n",
    "        items.append(item)\n",
    "        dates.append(item.datetime.date())\n",
    "\n",
    "print(f\"Found {len(items)} items\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600f3cfb-ce4e-4409-ae15-20f3a7107a62",
   "metadata": {},
   "source": [
    "To speed up processing in this example, we limit the number of chips to 3 per Sentinel-2 scene. Remove this limit in a real use case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "183975c7-8afb-49ef-8e70-790265719aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on <Item id=S2A_29SNB_20180828_1_L2A>\n",
      "Working on <Item id=S2B_29SNB_20180823_1_L2A>\n",
      "Working on <Item id=S2A_29SNB_20180818_1_L2A>\n",
      "Working on <Item id=S2B_29SNB_20180813_0_L2A>\n",
      "Working on <Item id=S2A_29SNB_20180808_1_L2A>\n",
      "Working on <Item id=S2B_29SNB_20180803_1_L2A>\n",
      "Working on <Item id=S2A_29SNB_20180729_1_L2A>\n",
      "Working on <Item id=S2B_29SNB_20180724_0_L2A>\n",
      "Working on <Item id=S2A_29SNB_20180719_0_L2A>\n",
      "Working on <Item id=S2B_29SNB_20180714_0_L2A>\n",
      "Working on <Item id=S2A_29SNB_20180709_0_L2A>\n",
      "Working on <Item id=S2B_29SNB_20180704_0_L2A>\n"
     ]
    }
   ],
   "source": [
    "chips = []\n",
    "datetimes = []\n",
    "bboxs = []\n",
    "chip_ids = []\n",
    "item_ids = []\n",
    "\n",
    "for item in items:\n",
    "    print(f\"Working on {item}\")\n",
    "\n",
    "    # Index the chips in the item\n",
    "    indexer = Sentinel2Indexer(item)\n",
    "\n",
    "    # Instanciate the chipper\n",
    "    chipper = Chipper(indexer, assets=[\"red\", \"green\", \"blue\", \"nir\", \"scl\"])\n",
    "\n",
    "    # Get first chip for the \"image\" asset key\n",
    "    for idx, (x, y, chip) in enumerate(chipper):\n",
    "        if idx > 2:\n",
    "            break\n",
    "        del chip[\"scl\"]\n",
    "        chips.append(chip)\n",
    "        datetimes.append(item.datetime)\n",
    "        bboxs.append(indexer.get_chip_bbox(x, y))\n",
    "        chip_ids.append((x, y))\n",
    "        item_ids.append(item.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71902ab7-3320-43cd-85c3-362c2500f241",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36, 4, 256, 256)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pixels = np.array([np.array(list(chip.values())).squeeze() for chip in chips])\n",
    "pixels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f7ce367-4e12-4648-bb79-119b4f50ead8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract mean, std, and wavelengths from metadata\n",
    "platform = \"sentinel-2-l2a\"\n",
    "# Retrieve the file content from the URL\n",
    "\n",
    "url = (\n",
    "    \"https://raw.githubusercontent.com/Clay-foundation/model/main/configs/metadata.yaml\"\n",
    ")\n",
    "response = requests.get(url, allow_redirects=True)\n",
    "\n",
    "# Convert bytes to string\n",
    "content = response.content.decode(\"utf-8\")\n",
    "\n",
    "# Load the yaml\n",
    "content = yaml.safe_load(content)\n",
    "\n",
    "metadata = Box(content)\n",
    "mean = []\n",
    "std = []\n",
    "waves = []\n",
    "# Use the band names to get the correct values in the correct order.\n",
    "for band in chips[0].keys():\n",
    "    mean.append(metadata[platform].bands.mean[band])\n",
    "    std.append(metadata[platform].bands.std[band])\n",
    "    waves.append(metadata[platform].bands.wavelength[band])\n",
    "\n",
    "# Prepare the normalization transform function using the mean and std values.\n",
    "transform = v2.Compose(\n",
    "    [\n",
    "        v2.Normalize(mean=mean, std=std),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8ec8c2d-ecb9-42a2-9e8c-3f95c67ef07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_timestamp(date):\n",
    "    week = date.isocalendar().week * 2 * np.pi / 52\n",
    "    hour = date.hour * 2 * np.pi / 24\n",
    "\n",
    "    return (math.sin(week), math.cos(week)), (math.sin(hour), math.cos(hour))\n",
    "\n",
    "\n",
    "times = [normalize_timestamp(dat) for dat in datetimes]\n",
    "week_norm = [dat[0] for dat in times]\n",
    "hour_norm = [dat[1] for dat in times]\n",
    "\n",
    "\n",
    "# Prep lat/lon embedding using the\n",
    "def normalize_latlon(lat, lon):\n",
    "    lat = lat * np.pi / 180\n",
    "    lon = lon * np.pi / 180\n",
    "\n",
    "    return (math.sin(lat), math.cos(lat)), (math.sin(lon), math.cos(lon))\n",
    "\n",
    "\n",
    "latlons = [normalize_latlon(lat, lon)] * len(times)\n",
    "lat_norm = [dat[0] for dat in latlons]\n",
    "lon_norm = [dat[1] for dat in latlons]\n",
    "\n",
    "# Prep gsd\n",
    "gsd = [10]\n",
    "\n",
    "# Normalize pixels\n",
    "pixels = transform(pixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2640eb17-a85c-4972-8d5d-e45e9ed8eba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "datacube = {\n",
    "    \"pixels\": torch.tensor(pixels, dtype=torch.float32),\n",
    "    \"time\": torch.tensor(np.hstack((week_norm, hour_norm)), dtype=torch.float32),\n",
    "    \"latlon\": torch.tensor(np.hstack((lat_norm, lon_norm)), dtype=torch.float32),\n",
    "    \"waves\": torch.tensor(waves, dtype=torch.float32),\n",
    "    \"gsd\": torch.tensor(gsd, dtype=torch.float32),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f6711a9-e7ed-44d5-add7-2c3a498cd422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pixels torch.Size([36, 4, 256, 256])\n",
      "time torch.Size([36, 4])\n",
      "latlon torch.Size([36, 4])\n",
      "waves torch.Size([4])\n",
      "gsd torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "for k, v in datacube.items():\n",
    "    print(k, v.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83243912-a2a8-4fa5-a39c-a9c3b07c7569",
   "metadata": {},
   "source": [
    "### Clay Embedder\n",
    "\n",
    "#### Load the embedder that is stored in ExportedProgram format using **cpu**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4eb468af-d468-46aa-a8fb-23ff95c56288",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -q https://huggingface.co/made-with-clay/Clay/resolve/main/compiled/v1.0/clay-v1-encoder-cpu.pt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9eb797f7-5238-49e0-9950-e85f10132454",
   "metadata": {},
   "outputs": [],
   "source": [
    "ep_embedder_cpu = torch.export.load(\"clay-v1-encoder-cpu.pt2\").module()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eefe4811-7290-47c3-a10e-45257e6d42e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 36s, sys: 26.9 s, total: 3min 3s\n",
      "Wall time: 51.3 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([36, 4, 256, 256]), torch.Size([36, 768]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "with torch.no_grad():\n",
    "    embeddings = ep_embedder_cpu(datacube)\n",
    "datacube[\"pixels\"].shape, embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e927b01-c855-4172-a4d9-2c10ba794ed4",
   "metadata": {},
   "source": [
    "For each chip, we have an embedding of size `768`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0810b4-34ad-490e-bbcd-c0c3288f017c",
   "metadata": {},
   "source": [
    "#### Load the embedder that is stored in ExportedProgram format using **gpu**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9c1bbfd4-7dc6-4ad0-8a0b-b3745a9f35ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -q https://huggingface.co/made-with-clay/Clay/resolve/main/compiled/v1.0/clay-v1-encoder.pt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e285a543-20ab-44ba-b676-2303284dc477",
   "metadata": {},
   "outputs": [],
   "source": [
    "datacube = {k: v.to(\"cuda\") for k, v in datacube.items()}\n",
    "ep_embedder = torch.export.load(\"clay-v1-encoder.pt2\").module()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "edefee90-e6b8-4701-bb5d-2bf7febc806c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 313 ms, sys: 41.5 ms, total: 354 ms\n",
      "Wall time: 239 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([36, 4, 256, 256]), torch.Size([36, 768]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "with torch.no_grad():\n",
    "    embeddings = ep_embedder(datacube)\n",
    "datacube[\"pixels\"].shape, embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196f2121-46b5-4b02-94d3-75e648c329c3",
   "metadata": {},
   "source": [
    "For each chip, we have an embedding of size `768`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1cb0f9-a434-419b-a88b-4d4edd84fea6",
   "metadata": {},
   "source": [
    "#### Load the embedder that is stored in ONNX format using **cpu**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aa10d696-740a-458e-ae10-eec9a43fb362",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "import onnxruntime as ort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "992524e5-2c2a-4e48-ae95-bd2aa87b72a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -q https://huggingface.co/made-with-clay/Clay/resolve/main/compiled/v1.0/clay-v1-encoder-cpu.onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dc3fa967-73d5-431c-88a2-84b088aff06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "datacube = {k: v.to(\"cpu\") for k, v in datacube.items()}\n",
    "onnx_embedder = ort.InferenceSession(\n",
    "    \"clay-v1-encoder-cpu.onnx\", providers=[\"CPUExecutionProvider\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "24591d17-d1c8-452b-9b20-676a9b6f8643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 48s, sys: 1.82 s, total: 3min 50s\n",
      "Wall time: 30.6 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(36, 768)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "embeddings = onnx_embedder.run(\n",
    "    [],\n",
    "    {\n",
    "        \"cube\": datacube[\"pixels\"].numpy(),\n",
    "        \"time\": datacube[\"time\"].numpy(),\n",
    "        \"latlon\": datacube[\"latlon\"].numpy(),\n",
    "        \"waves\": datacube[\"waves\"].numpy(),\n",
    "        \"gsd\": datacube[\"gsd\"].numpy(),\n",
    "    },\n",
    ")[0]\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c07216e-a109-4cd8-8c74-9a3fc9a37757",
   "metadata": {},
   "source": [
    "For each chip, we have an embedding of size `768`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8d5900-9a4b-4e2d-b992-4fb0a1e8c835",
   "metadata": {},
   "source": [
    "### Store the results\n",
    "\n",
    "We create a table containing the embeddings, bounding box, the STAC item ID, the datetime of the image capture, and the chip x and y ids. Then we save that data to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "677f04d3-db38-4d44-9b55-c103d54adcd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyarrow.Table\n",
       "datetimes: timestamp[us, tz=UTC]\n",
       "chip_ids: list<item: int64>\n",
       "  child 0, item: int64\n",
       "item_ids: string\n",
       "emeddings: list<item: float>\n",
       "  child 0, item: float\n",
       "geometry: extension<geoarrow.polygon<PolygonType>>\n",
       "----\n",
       "datetimes: [[2018-08-28 11:30:56.771000Z,2018-08-28 11:30:56.771000Z,2018-08-28 11:30:56.771000Z,2018-08-23 11:30:50.574000Z,2018-08-23 11:30:50.574000Z,...,2018-07-09 11:24:55.535000Z,2018-07-09 11:24:55.535000Z,2018-07-04 11:30:35.271000Z,2018-07-04 11:30:35.271000Z,2018-07-04 11:30:35.271000Z]]\n",
       "chip_ids: [[[0,0],[1,0],...,[1,0],[2,0]]]\n",
       "item_ids: [[\"S2A_29SNB_20180828_1_L2A\",\"S2A_29SNB_20180828_1_L2A\",\"S2A_29SNB_20180828_1_L2A\",\"S2B_29SNB_20180823_1_L2A\",\"S2B_29SNB_20180823_1_L2A\",...,\"S2A_29SNB_20180709_0_L2A\",\"S2A_29SNB_20180709_0_L2A\",\"S2B_29SNB_20180704_0_L2A\",\"S2B_29SNB_20180704_0_L2A\",\"S2B_29SNB_20180704_0_L2A\"]]\n",
       "emeddings: [[[-0.14773342,0.08466571,0.13797832,0.11150883,0.06517959,...,0.036681578,-0.092160255,0.025934512,-0.12496276,-0.034070153],[-0.14430065,0.085857555,0.13839196,0.10963549,0.0652737,...,0.03711322,-0.09153629,0.02631686,-0.12422915,-0.03333628],...,[-0.09626354,0.062443394,0.24817112,0.012715777,0.043093704,...,0.011770063,-0.037860263,0.027813748,-0.11962952,-0.02246455],[-0.10004063,0.06320572,0.24851695,0.012129029,0.043350283,...,0.011444314,-0.03733269,0.027787287,-0.12139094,-0.021088997]]]\n",
       "geometry: [[[      -- is_valid: all not null\n",
       "      -- child 0 type: double\n",
       "[-8.825403979293151,-8.825730459265694,-9.000227209792856,-9.000227635454767,-8.825403979293151]\n",
       "      -- child 1 type: double\n",
       "[37.947460030545635,37.809019655564406,37.809148556380286,37.947589571562965,37.947460030545635]],[      -- is_valid: all not null\n",
       "      -- child 0 type: double\n",
       "[-8.650582567535476,-8.651235936821893,-8.825730459265694,-8.825403979293151,-8.650582567535476]\n",
       "      -- child 1 type: double\n",
       "[37.94707073614538,37.80863228507305,37.809019655564406,37.947460030545635,37.94707073614538]],...,[      -- is_valid: all not null\n",
       "      -- child 0 type: double\n",
       "[-8.650582567535476,-8.651235936821893,-8.825730459265694,-8.825403979293151,-8.650582567535476]\n",
       "      -- child 1 type: double\n",
       "[37.94707073614538,37.80863228507305,37.809019655564406,37.947460030545635,37.94707073614538]],[      -- is_valid: all not null\n",
       "      -- child 0 type: double\n",
       "[-8.475765647330832,-8.476745873271028,-8.651235936821893,-8.650582567535476,-8.475765647330832]\n",
       "      -- child 1 type: double\n",
       "[37.94642170369997,37.80798646012822,37.80863228507305,37.94707073614538,37.94642170369997]]]]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write data to pyarrow table\n",
    "index = {\n",
    "    \"datetimes\": datetimes,\n",
    "    \"chip_ids\": chip_ids,\n",
    "    \"item_ids\": item_ids,\n",
    "    \"emeddings\": [np.ascontiguousarray(dat) for dat in embeddings],\n",
    "    \"geometry\": ga.as_geoarrow([dat.wkt for dat in bboxs]),\n",
    "}\n",
    "table = pa.table(index)\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d62a9e8a-b4f9-491c-a437-6a164a9e74fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "pq.write_table(table, \"embeddings.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30fb8c7-d04d-453f-93f6-dc3599f1df15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
